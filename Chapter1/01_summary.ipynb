{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "<h2>Structure of chapters</h2>\n",
    "<ul>\n",
    "<li>We will use new.py to ....</li>\n",
    "<li>It is </li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "## files hello.py\n",
    "\n",
    "## test.py\n",
    "\n",
    "## Makefile\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Chapter 1: How to write and test a Python program</h2>\n",
    "<ul>\n",
    "<li>Write a Python program to say “Hello, World!”</li>\n",
    "<li>Handle command-line arguments using <i><b>argparse</b></i>  </li>\n",
    "<li>Run tests for the code with Pytest</li>\n",
    "<li>Learn about <i><b>$PATH</b></i> </li>\n",
    "<li>Use tools like YAPF and Black to format the code</li>\n",
    "<li>Use tools like Flake8 and Pylint to find problems in\n",
    "the code</li>\n",
    "<li>Use the new.py program to create new programs</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Purpose</h2>\n",
    "<ul>\n",
    "<li>Reviewing why Fully Connected Neural networks are not good choices when analying imaging data</li>\n",
    "<li>Understanding convolution and why convolutional neural networks are better choice when creating models for imaging data </li>\n",
    "<li>Creating a CNN</li>\n",
    "<li>Understanding the difference between the module and the functional APIs</li>\n",
    "<li>Designing a neural network</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s very important to create the hello.py file inside the 01_hello directory so that the test.py program can find it.\n",
    "\n",
    "Once you’ve started a new file, add this line:\n",
    "        print('Hello, World!')\n",
    "        \n",
    "Open a terminal window in VS Code or PyCharm or in some other terminal, and navigate to the directory where your hello.py program is located. You can run it with the command python3 hello.py—this causes Python version 3 to execute the commands in the file named hello.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ####  Testing your program\n",
    "The most fundamental idea I want to teach you is how to test your programs. I’ve writ- ten a test.py program in the 01_hello directory that we can use to test our new hello.py program.\n",
    "We will use pytest to execute all the commands and tell us how many tests we passed. We’ll include the -v option, which tells pytest to create “verbose” output. If you run it like this, you should see the following output as the first several lines. After that will follow many more lines showing you more information about the tests that didn’t pass.\n",
    "\n",
    "#### pytest -v test.py\n",
    "\n",
    "We will use pytest to execute all the commands and tell us how many tests we passed. We’ll include the -v option, which tells pytest to create “verbose” output. If you run it like this, you should see the following output as the first several lines. After that will follow many more lines showing you more information about the tests that didn’t pass.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python3  --> The shebang line tells the operating system to  use /usr/bin/env \n",
    "# ---->to find python3 to interpret this program.\n",
    "\n",
    "\n",
    "#---> A comment line documenting the purpose of the program\n",
    "\"\"\"tests for hello.py\"\"\"\n",
    "\n",
    "import os\n",
    "from subprocess import getstatusoutput, getoutput\n",
    "\n",
    "prg = './hello.py'\n",
    "# here . dot means the current working directory\n",
    "#  and slash / means is how we seperate eah directory\n",
    "#  from each other\n",
    "\n",
    "# The first test always checks that the expected file exists. Here the test looks for hello.py.\n",
    "# --------------------------------------------------\n",
    "def test_exists():\n",
    "    \"\"\"exists\"\"\"\n",
    "\n",
    "    assert os.path.isfile(prg)\n",
    "\n",
    "\n",
    "    # The second test tries to run the program with python3 hello.py and then checks if the program printed “Hello, World!” If you miss even one character, like forgetting a comma, the test will point out the error, so read carefully!\n",
    "\n",
    "# --------------------------------------------------\n",
    "def test_runnable():\n",
    "    \"\"\"Runs using python3\"\"\"\n",
    "\n",
    "    out = getoutput(f'python3 {prg}')\n",
    "    assert out.strip() == 'Hello, World!'\n",
    "\n",
    "\n",
    "    # The third test checks that the program is “executable.” This test fails, so next we’ll talk about how to make that pass.\n",
    "# --------------------------------------------------\n",
    "def test_executable():\n",
    "    \"\"\"Says 'Hello, World!' by default\"\"\"\n",
    "\n",
    "    out = getoutput(prg)\n",
    "    assert out.strip() == 'Hello, World!'\n",
    "\n",
    "\n",
    "    # The fourth test asks the program for help and doesn’t get anything. We’re going to add the ability to print a “usage” statement that describes how to use our program.\n",
    "\n",
    "# --------------------------------------------------\n",
    "def test_usage():\n",
    "    \"\"\"usage\"\"\"\n",
    "\n",
    "    for flag in ['-h', '--help']:\n",
    "        rv, out = getstatusoutput(f'{prg} {flag}')\n",
    "        assert rv == 0\n",
    "        assert out.lower().startswith('usage')\n",
    "\n",
    "\n",
    "        # The last test checks that the program can greet a name that we’ll pass as an argument. Since our program doesn’t yet accept arguments, we’ll need to add that, too.\n",
    "# --------------------------------------------------\n",
    "def test_input():\n",
    "    \"\"\"test for input\"\"\"\n",
    "\n",
    "    for val in ['Universe', 'Multiverse']:\n",
    "        for option in ['-n', '--name']:\n",
    "            rv, out = getstatusoutput(f'{prg} {option} {val}')\n",
    "            assert rv == 0\n",
    "            assert out.strip() == f'Hello, {val}!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Provide some  explanation about the error:\n",
    "\n",
    "page 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the #! (shebang) line\n",
    "\n",
    "It’s common to put a special comment line in programs like these to indicate which language needs to be used to execute the commands in the file.\n",
    "This\n",
    "\n",
    "This comment line starts off with #!,\n",
    "and the nickname for this is “shebang” (pro- nounced “shuh-bang”—I always think of the # as the “shuh” and the ! as the “bang!”). Just as with any other comment, Python will ignore the shebang, but the operating sys- tem (like macOS or Windows) will use it to decide which program to use to run the rest of the file.\n",
    "Here is the shebang you should add:\n",
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpfull commend line\n",
    "\n",
    "You can use the which command to see which python3 it finds:\n",
    "$ which python3 /Library/Frameworks/Python.framework/Versions/3.8/bin/python3\n",
    "\n",
    "You can use the env command to find and run programs. If you run env python3, it will run a python3 program if it can find one. Here’s what I see on my computer:\n",
    "\n",
    "\n",
    "my program would not work on another computer that has python3 installed in a dif- ferent location. I doubt it would work on your computer, either. This is why you should always use the env program to find the python3 that is specific to the machine on which it’s running.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a program executable\n",
    "\n",
    "So far we’ve been explicitly telling python3 to run our pro- gram, but since we added the shebang, we can execute the program directly and let the OS figure out that it should use python3. The advantage of this is that we could copy our pro- gram to a directory where other programs live and execute it from anywhere on our computer.\n",
    "The first step in doing this is to make our program “execut- able” using the command chmod (change mode). Think of it as turning your program “on.” Run this command to make hello.py executable:\n",
    "\n",
    "chmod +x hello.py\n",
    "\n",
    "The +x will add an “executable” attribute to the file.\n",
    "\n",
    "\n",
    "Now you can run the program like so:\n",
    "$ ./hello.py\n",
    "\n",
    "The ./ is the current directory, and it’s necessary to run a program when you are in the same directory as the program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding $PATH\n",
    "\n",
    "ne of the biggest reasons to set the shebang line and make your program executable is so that you can install your Python programs just like other commands and pro- grams. We used the which command earlier to find the location of python3 on the Repl.it instance:\n",
    "$ which python3 /home/runner/.local/share/virtualenvs/python3/bin/python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How was the env program able to find it? Windows, macOS, and Linux all have a $PATH variable, which is a list of directories the OS will look in to find a program. For instance, here is the $PATH for my Repl.it instance:\n",
    "> echo $PATH /home/runner/.local/share/virtualenvs/python3/bin:/usr/local/bin:\\ /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span style='color:green;'>Alternative solution:</span> Using <span style='color:red;'>convolution</span>, which is a different linear operation.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Why FCNs are not good choices for analyzing images?</h3>\n",
    "<ul>\n",
    "    <li>FCNs have too many parameters. As such, they can memorize the details of the training set, and therefore the the resulted models, most probably, will not be generalized well.</li>\n",
    "    <li>Another issue with having too many parameters is that such a network is computationally expensive to train. </li>\n",
    "    <li>Every pixel is related to all other pixels regardless of their locations. Therefore, FCNs are not able to capture local patterns</li>\n",
    "</ul>\n",
    "<p><span style='color:green;'>Alternative solution:</span> Using <span style='color:red;'>convolution</span>, which is a different linear operation.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>How CNN tackles the above issues?</h3>\n",
    "<p><b>Learning more with less number of parameters:</b> Kernels are one of the main building blocks of the CNNs Kernels are small matrices; therefore, CNNs are able to learn features with smaller numbers of parameters. </p>\n",
    "<p><b>Downsampling:</b> CNNs use downsampling methods, such as maxpooling or average pooling, to keep and send the most informative part of the image to the next layer through less number of parameters. </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convolution</h3>\n",
    "<p>The main building blocks of CNNs are <span style='background-color:yellow'><b>kernels</b></span>. In image processing, a kernel is a 2D (or 3D in the case of colored images) signal or a matrix which is used for different purposes, such as sharpening, blurring, edge detection. In a CNN model a kernel enables to capture similar patterns across an image regardless of their locations. This property is called 'translation invariant' by the book. To explain more, a kernel slides over an image and the elements of the kernel (remember that a kernel is a matrix) are convolved with the pixels of the image. Thus, one of the main operations in a CNN is convolution and hence the name of these types of neural networks.     \n",
    "<br/>\n",
    "    </p>\n",
    "    <p>\n",
    "<b>Notes</b>\n",
    "    <ul>\n",
    "        <li>In the context of CNNs, a kernel is called <span style='background-color:yellow'><b>Channel</b></span> too. An RGB colored image has three channels, red, green, and blue, meaning there are three values associated with every pixels. Similarly, a CNN has several channels at every convolutional layer. Each of these channels or kernels are responsible to learn a specific pattern.</li>\n",
    "        <li>At every layer, a CNN has several kernels and hence is able to capture more than one pattern.</li>\n",
    "        <li>Although there are several kernels at every layer, the size of the kernels is small (e.g., 3*3 or 5*5). Thus, a CNN model can have a much smaller set of parameters in comparison with an FCN, but still be able to reach better results.</li>\n",
    "        <li>Having several layers each of which consisting several kernels can be interpreted as transforming an image with multiple channels to another one again with multiple channels.</li>\n",
    "        <li><i><b>torch.nn</b></i> modules provides several modules to perform convolution; <i><b>nn.Conv1d</b></i> for timeseries or 1D signals, <i><b>nn.Conv2d</b></i> for images or <i><b>2D signals</b></i>, and <i><b>nn.Conv3d</b></i> for volums and videos or 3D signals</li>\n",
    "    </ul>\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Downsampling</h3>\n",
    "<ul>\n",
    "    <li><b>Averaging pooling:</b> Averaging pixels within a specified window to create one pixel value results in reducing the size of an image. To illustrate, performin average pooling within a window of size 2*2 means we take average over the four pixels within this window. Every four pixels are mapped to one pixel value. Therefore, an image of size 4*4 with 16 pixels is transformed to a 2*2 image with 4 pixels. </li>\n",
    "    <li><b>Maxpooling:</b> This operation is similar to average pooling but rather than taking average, the maximum pixel value will be selected within the specified window.</li>\n",
    "    <li><b>Striding:</b> If we use steps with size bigger than one when sliding a kernel over an image, the result will be an image with the size smaller that the original image.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deeper layers generate more complx features</h3>\n",
    "<p>\n",
    " At every layer, the network tries to compact information within less parameters and send it over deeper layers. As a result we can say that kernels in the first layers operates over small neighboring pixels while kernels deeper within the network work are looking at the compacted information generated by previous layers. Therefore, the deeper layers can capture more complex patters and features by looking a wider range of pixels than the kernels in the first layers.\n",
    "</p>\n",
    "<p>\n",
    "<b>Receptive field:</b> The number of input pixels that a layer uses to produce one output pixel is called receptive field.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building a CNN </h2>\n",
    "<p>In the rest of the article, we will see how to build a CNN with two approaches; 1) using nn.Sequential module and 2) as a subclass of nn.Module.  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building a CNN using nn.Sequential module</h3>\n",
    "<p>Puttng together all the concepts above, a CNN is a <span style='background-color:yellow'><i>sequence</i></span> of layers consisting several <i><b>kernels</b></i> to perform <i><b>convolution</b></i>, activation functions, and pooling operations. Let's create a simple model. Before that, we need toprepare the dataset. Similar to Chapter 7, we will work on CIFAR2 data which we creat from CIFAR10 by including only two categories of images and excluding the rest.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cifar_mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
    "cifar_std = torch.tensor([0.2470, 0.2435, 0.2616])\n",
    "#transform = transforms.compose([transforms.ToTensor(), transforms.Normalize(mean = cifar_mean, std = cifar_std)])\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=cifar_mean, std=cifar_std)])\n",
    "cifar10 = CIFAR10('/Users/lidasafarnejad/PycharmProjects/pytorchBook/data', train=True, download=False, transform = transform)\n",
    "cifar10_val = CIFAR10('/Users/lidasafarnejad/PycharmProjects/pytorchBook/data', train=False, download = False, transform=transform)\n",
    "label_map = {0:1, 2:1}\n",
    "class_names = ['aiplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in label_map]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in label_map]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "sample_img, sample_label = cifar2[0]\n",
    "print(sample_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here is the model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Size of the image after the first convolution layer: (32-3+2)/1 + 1= 32\n",
    "# Size of the image after the first maxpooling operation: 32 / 2 = 16\n",
    "# Size of the image after the second convolution layer: (16-3+2)/1 + 1 = 16\n",
    "# Size of the image after the second maxpooling operation: 16 / 2 = 8\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,16,kernel_size=(3,3), stride=1, padding=1), \n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16,8,kernel_size=(3,3),stride=1, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(8*8*8, 2)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'><b>Notes:</b></span> \n",
    "<ul>\n",
    "    <li>Size of the output of a convolutional layer with the kernel size $k$ and stride $s$ is calculate using  the following formula:\n",
    "        $$\\frac{(w-k+2*p)}{s},$$\n",
    "        where $w$ is the width of the image and $p$ is the size of the padding. Here we assume that height and width of the image are the same. If not, to calculate the height after applying convolution, $w$ must be substitude via $h$ (height) of the image.</li>\n",
    "    <li>In the above simple model, pay attention to <i><b>nn.Flatten()</b></i> coming after the last maxpooling operation and before the linear layer. The output of the last maxpooling layer is still an image or a 2D array that cannot be consumed by the next LINEAR layer which expects 1D input. Hence, we must use nn.Flatten() in between.</li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0844, -0.0861]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample_img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building a CNN as a subclass of nn.Module</h3>\n",
    "<p>While nn.Sequential is a useful tool for building CNNs, there are some scenarios where we need more flexibility to create custom network architectures. In these cases, using a predefined class like nn.Sequential, which is a subclass of nn.Module, may not provide the necessary degree of flexibility. In such scenarios we can build our own class as a subclass of nn.Module.</p>\n",
    "<p> nn.Module is an <i><b>abstract</b></i> class meaning it cannot be instantiated but it provides some useful concrete methods and also some abstract methods. A subclass of an abstract class must implement the abstract methods of its parent abstract class. Please note that when you define an abstract class, you specify a set of methods that must be implemented by any concrete subclass of the abstract class. However, a concrete subclass is free to add additional methods beyond those specified in the abstract class, as long as it implements all of the abstract methods as required. Interested readers can visit <a href='https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py'>this link</a> for the implementation of the nn.Module.</p>\n",
    "<p>Now that know what nn.Module is, let's use it to define a CNN class: </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=(3,3), padding=1)\n",
    "        self.fc1 = nn.Linear(16*8*8,32)\n",
    "        self.fc2 = nn.Linear(32,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)),2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)),2)\n",
    "        out = out.view(-1,16*8*8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "        \n",
    "model = CNN_net()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the above example, we define our CNN network as a subclass of nn.Module, and then create an object of this class to represent our model. </p>\n",
    "<p><b><span style='color:red;'>Note:</span></b> When defining a network using nn.Module, it is necessary to implement the <i><b>forward</b></i> method, which defines the forward pass of the network.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Nested Modules in Pytorch</h3>\n",
    "<p>In PyTorch, a module is a subclass of the nn.Module class, which represents a building block of a neural network. A module can be a single layer, a group of layers, or even an entire neural network. As an example, CNN_net in the above example is a module. A submodule is a module that is assigned as an attribute of another module. In other words, when you define a module as an attribute of another module, it becomes a submodule of the parent module. In the above example, an instance of the nn.Conv2d module, which is already a module or a subclass of the nn.Module, is assigned as one of the attributes of the CNN_net; thus, it is one of the submodules of CNN_net. </p>\n",
    "<p>When a module is assigned to be an attribute of a module and hence becomes submodule of the other class, it is <b>registered</b> or in other words, added to dictionary of the parent class. In the CNN_net example, Conv2d is registered as one the child modules of the parent module CNN_net. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the parameters() method of the model, it goes through all of the submodules and call their parameters() methods recursively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38386, [864, 32, 4608, 16, 32768, 32, 64, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()] \n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The functional API</h3>\n",
    "<p>\n",
    "        <i><b>nn.Module</b></i> is an abstract class and other modules such as <i><b>nn.Linear</b></i> and <i><b>nn.Sequential</b></i> are subclasses of it. We also saw that a customized classes that we designed are also subclasses of <i><b>nn.Module</b></i>. Therefore, they can be considered to be modules. A module, as the way defined in the book, can have a state and a set of parameters. Keeping this in mind, when performing some operations such as <i><b>nn.MaxPool2d</b></i>, we don't really need to keep track of their states or even store any parameters associated with them. As such, considering them as modules is somehow overkill and hence the pytorch functional API comes to the scene. As stated in the book, '<span style='background-color:yellow;'><i>functional</i> here means 'having no state.</span> Thus, the rule of thumb is that when we want to simply perfom an operation, use the methods (functions) of <b><i>nn.functional</i></b>, such as <i><b>nn.functional.max_pool2d</b></i> rather than <i><b>nn.MaxPool2d</b></i>\n",
    "    <br/>\n",
    "    However, when keeping track of the state and parameters is important, we should use modules of <b><i>nn</i></b> rather than the functional API. As an example, the recommendation is to use <i><b>nn.Linear</b></i> rather than its counterpart <b><i>nn.functional.linear</i></b>.\n",
    "</p>\n",
    "<p><b><span style='color:red;'>Note:</span></b> Some functional tools, such as <b><i>nn.functional.tanh</i></b>, have been depricated and the recommendation is not using them eventhough they are more like a function rather than a module. Interested readers can read <a url='https://discuss.pytorch.org/t/torch-tanh-vs-torch-nn-functional-tanh/15897'>this thread</a> in the Pytorch forum.</p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training the model</h3>\n",
    "<p>Now that we have the model, let's train it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "train_loader = DataLoader(cifar2, batch_size=16)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = ('GPU' if torch.cuda.is_available() else 'cpu')\n",
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    for img, label in train_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(img)\n",
    "        loss = criterion(output,label)\n",
    "        loss_list.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>More to read:</h3>\n",
    "    <a>https://discuss.pytorch.org/t/torch-tanh-vs-torch-nn-functional-tanh/15897</a>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
